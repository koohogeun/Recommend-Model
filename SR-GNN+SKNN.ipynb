{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05847d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "going-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import cknn\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import DataFormatterEditAddSession as DataFormatterA\n",
    "import DataFormatterEdit as DataFormatter\n",
    "\n",
    "from model import *\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import build_graph, split_validation, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "harmful-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_data(data, str_):\n",
    "    values = data.loc[:,[str_]].values\n",
    "    values = values.reshape(-1,)\n",
    "    new = np.unique(values)\n",
    "    return new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authentic-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 5\n",
    "#_path = 'amz_data_prep_2018_book.csv'\n",
    "_path = 'amz_data_prep_2018_book_40k.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indonesian-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pd_data_frame(train_data, session_key='session_id', item_key='item_id', time_key='eventdate'):\n",
    "    df = pd.DataFrame({session_key:[], item_key:[], time_key:[]})\n",
    "    ses_ids = []\n",
    "    ses_dates = []\n",
    "    ses_seqs = []\n",
    "    for ses_id, ses_date, ses_seq in tqdm(zip(train_data[0], train_data[1], train_data[2]), total=len(train_data[0])):\n",
    "        for ses_ in ses_seq:\n",
    "            ses_date_ = int(ses_date.astype(np.float))\n",
    "            ses_ids.append(int(ses_id))\n",
    "            ses_dates.append(ses_date_)\n",
    "            ses_seqs.append(ses_)\n",
    "    ses_ids = np.asarray(ses_ids)\n",
    "    ses_dates = np.asarray(ses_dates)\n",
    "    ses_seqs = np.asarray(ses_seqs)\n",
    "    d = np.concatenate((ses_ids,ses_seqs,ses_dates))\n",
    "    d = np.reshape(d,(3,-1))\n",
    "    d = d.T\n",
    "    column_names = [session_key, item_key, time_key]\n",
    "    df = pd.DataFrame(d, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b350a-efb4-47ab-b802-c302b0a95c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(_path, delimiter=',')\n",
    "n_item = num_data(data, 'item_id')\n",
    "k_split_data_list, sess_clicks = DataFormatterA.get_k(_path, fold)\n",
    "last_sr_gnn_hit, sr_gnn_hit, iknn_hit, final_hit, last_sr_gnn_mrr, sr_gnn_mrr, iknn_mrr, final_mrr = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02734d75-0f55-49f2-bfd1-2acb82227fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for __p in range(5):\n",
    "    avg_p = []\n",
    "    avg_m = []\n",
    "    for fold_ in range(fold):\n",
    "        gc.collect()\n",
    "        test_data_preproc = k_split_data_list[fold_]\n",
    "        train_data_preproc = k_split_data_list.copy()\n",
    "        del train_data_preproc[fold_]\n",
    "        train_data_ = _ = train_data = test_data = df = knn = mrr_20 = p_20 = scr = scr_convd = slices = None\n",
    "\n",
    "        train_data_preproc, test_data_preproc, train_data_, _ = DataFormatterA.make_tr_ts_data_set(train_data_preproc, \n",
    "                                                                                                      test_data_preproc, \n",
    "                                                                                                      sess_clicks)\n",
    "\n",
    "        train_data = Data(train_data_preproc, shuffle=True)\n",
    "        test_data = Data(test_data_preproc, shuffle=False)\n",
    "        #test_data.inputs.shape\n",
    "        #train_data_preproc = [[subset],[ans_items]]\n",
    "        #train_data_ = [[session_id],[session_date],[item_seq]]\n",
    "        #train_data = obj\n",
    "        n_node = n_item+1\n",
    "\n",
    "        model = trans_to_cuda(SessionGraph(n_node))\n",
    "\n",
    "        best_result = [0, 0]\n",
    "        best_epoch = [0, 0]\n",
    "        bad_counter = 0\n",
    "\n",
    "        for epoch in range(20):\n",
    "            hit, mrr = train_test(model, train_data, test_data)\n",
    "            flag = 0\n",
    "            if hit > best_result[0]:\n",
    "                best_result[0] = hit\n",
    "                best_epoch[0] = epoch\n",
    "                flag = 1\n",
    "            if mrr > best_result[1]:\n",
    "                best_result[1] = mrr\n",
    "                best_epoch[1] = epoch\n",
    "                flag = 1\n",
    "            bad_counter += 1 - flag\n",
    "            if bad_counter >= 5:\n",
    "                break\n",
    "        print('-------------------------------------------------------')\n",
    "        last_sr_gnn_hit.append(hit)\n",
    "        last_sr_gnn_mrr.append(mrr)\n",
    "\n",
    "        df = make_pd_data_frame(train_data_)\n",
    "        knn = cknn.ContextKNN(data = df, session_key='session_id', item_key='item_id', time_key='eventdate')\n",
    "\n",
    "        mrr_20, p_20, scr = knn.multi_predict_ts_data(test_data, 12)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        hit, mrr = [], []\n",
    "        slices = test_data.generate_batch(model.batch_size)\n",
    "\n",
    "        for i in tqdm(slices):\n",
    "            targets, scores = forward(model, i, test_data)\n",
    "            scores = trans_to_cpu(scores).detach().numpy()\n",
    "            for j, idx in enumerate(i):\n",
    "                v = scr[idx][0]\n",
    "                for index, val in zip(list(v.keys()), list(v.values())):\n",
    "                    scores[j,index-1] += val\n",
    "            scores = torch.Tensor(scores)\n",
    "            sub_scores = scores.topk(20)[1]\n",
    "            sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "            for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "                hit.append(np.isin(target - 1, score))\n",
    "                if len(np.where(score == target - 1)[0]) == 0:\n",
    "                    mrr.append(0)\n",
    "                else:\n",
    "                    mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "\n",
    "        final_hit.append(np.mean(hit)*100)\n",
    "        final_mrr.append(np.mean(mrr)*100)\n",
    "\n",
    "        sr_gnn_hit.append(best_result[0])\n",
    "        sr_gnn_mrr.append(best_result[1])\n",
    "\n",
    "        iknn_hit.append(p_20)\n",
    "        iknn_mrr.append(mrr_20)\n",
    "    print()\n",
    "    print('SR-GNN Score: ', np.mean(last_sr_gnn_hit), np.mean(last_sr_gnn_mrr))\n",
    "    print('SR-GNN Last Score: ', np.mean(sr_gnn_hit), np.mean(sr_gnn_mrr))\n",
    "    print('CKNN Score: ', np.mean(iknn_hit), np.mean(iknn_mrr))\n",
    "    print('Proposed Method Score: ',np.mean(final_hit), np.mean(final_mrr))\n",
    "    avg_p.append(np.mean(final_hit))\n",
    "    avg_m.append(np.mean(final_mrr))\n",
    "print('Method 1 Avg Proposed Method Score: ',np.mean(avg_p), np.mean(avg_m))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bd281-4c0e-4af0-a4bc-5d95b646a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "for __p in range(5):\n",
    "    avg_p = []\n",
    "    avg_m = []\n",
    "    for fold_ in range(fold):\n",
    "        gc.collect()\n",
    "        test_data_preproc = k_split_data_list[fold_]\n",
    "        train_data_preproc = k_split_data_list.copy()\n",
    "        del train_data_preproc[fold_]\n",
    "        train_data_ = _ = train_data = test_data = df = knn = mrr_20 = p_20 = scr = scr_convd = slices = None\n",
    "\n",
    "        train_data_preproc, test_data_preproc, train_data_, _ = DataFormatterA.make_tr_ts_data_set(train_data_preproc, \n",
    "                                                                                                      test_data_preproc, \n",
    "                                                                                                      sess_clicks)\n",
    "\n",
    "        train_data = Data(train_data_preproc, shuffle=True, method=0)\n",
    "        test_data = Data(test_data_preproc, shuffle=False)\n",
    "        #test_data.inputs.shape\n",
    "        #train_data_preproc = [[subset],[ans_items]]\n",
    "        #train_data_ = [[session_id],[session_date],[item_seq]]\n",
    "        #train_data = obj\n",
    "        n_node = n_item+1\n",
    "\n",
    "        model = trans_to_cuda(SessionGraph(n_node))\n",
    "\n",
    "        best_result = [0, 0]\n",
    "        best_epoch = [0, 0]\n",
    "        bad_counter = 0\n",
    "\n",
    "        for epoch in range(20):\n",
    "            hit, mrr = train_test(model, train_data, test_data)\n",
    "            flag = 0\n",
    "            if hit > best_result[0]:\n",
    "                best_result[0] = hit\n",
    "                best_epoch[0] = epoch\n",
    "                flag = 1\n",
    "            if mrr > best_result[1]:\n",
    "                best_result[1] = mrr\n",
    "                best_epoch[1] = epoch\n",
    "                flag = 1\n",
    "            bad_counter += 1 - flag\n",
    "            if bad_counter >= 5:\n",
    "                break\n",
    "        print('-------------------------------------------------------')\n",
    "        last_sr_gnn_hit.append(hit)\n",
    "        last_sr_gnn_mrr.append(mrr)\n",
    "\n",
    "        df = make_pd_data_frame(train_data_)\n",
    "        knn = cknn.ContextKNN(data = df, session_key='session_id', item_key='item_id', time_key='eventdate')\n",
    "\n",
    "        mrr_20, p_20, scr = knn.multi_predict_ts_data(test_data, 12)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        hit, mrr = [], []\n",
    "        slices = test_data.generate_batch(model.batch_size)\n",
    "\n",
    "        for i in tqdm(slices):\n",
    "            targets, scores = forward(model, i, test_data)\n",
    "            scores = trans_to_cpu(scores).detach().numpy()\n",
    "            for j, idx in enumerate(i):\n",
    "                v = scr[idx][0]\n",
    "                for index, val in zip(list(v.keys()), list(v.values())):\n",
    "                    scores[j,index-1] += val\n",
    "            scores = torch.Tensor(scores)\n",
    "            sub_scores = scores.topk(20)[1]\n",
    "            sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "            for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "                hit.append(np.isin(target - 1, score))\n",
    "                if len(np.where(score == target - 1)[0]) == 0:\n",
    "                    mrr.append(0)\n",
    "                else:\n",
    "                    mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "\n",
    "        final_hit.append(np.mean(hit)*100)\n",
    "        final_mrr.append(np.mean(mrr)*100)\n",
    "\n",
    "        sr_gnn_hit.append(best_result[0])\n",
    "        sr_gnn_mrr.append(best_result[1])\n",
    "\n",
    "        iknn_hit.append(p_20)\n",
    "        iknn_mrr.append(mrr_20)\n",
    "    print()\n",
    "    print('SR-GNN Score: ', np.mean(last_sr_gnn_hit), np.mean(last_sr_gnn_mrr))\n",
    "    print('SR-GNN Last Score: ', np.mean(sr_gnn_hit), np.mean(sr_gnn_mrr))\n",
    "    print('CKNN Score: ', np.mean(iknn_hit), np.mean(iknn_mrr))\n",
    "    print('Proposed Method Score: ',np.mean(final_hit), np.mean(final_mrr))\n",
    "    avg_p.append(np.mean(final_hit))\n",
    "    avg_m.append(np.mean(final_mrr))\n",
    "print('Method 2 Avg Proposed Method Score: ',np.mean(avg_p), np.mean(avg_m))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17439729-e4a1-4bcd-bdc6-ed8446ffab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for __p in range(5):\n",
    "    avg_p = []\n",
    "    avg_m = []\n",
    "    for fold_ in range(fold):\n",
    "        gc.collect()\n",
    "        test_data_preproc = k_split_data_list[fold_]\n",
    "        train_data_preproc = k_split_data_list.copy()\n",
    "        del train_data_preproc[fold_]\n",
    "        train_data_ = _ = train_data = test_data = df = knn = mrr_20 = p_20 = scr = scr_convd = slices = None\n",
    "\n",
    "        train_data_preproc, test_data_preproc, train_data_, _ = DataFormatterA.make_tr_ts_data_set(train_data_preproc, \n",
    "                                                                                                      test_data_preproc, \n",
    "                                                                                                      sess_clicks)\n",
    "\n",
    "        train_data = Data(train_data_preproc, shuffle=True, method=1)\n",
    "        test_data = Data(test_data_preproc, shuffle=False)\n",
    "        #test_data.inputs.shape\n",
    "        #train_data_preproc = [[subset],[ans_items]]\n",
    "        #train_data_ = [[session_id],[session_date],[item_seq]]\n",
    "        #train_data = obj\n",
    "        n_node = n_item+1\n",
    "\n",
    "        model = trans_to_cuda(SessionGraph(n_node))\n",
    "\n",
    "        best_result = [0, 0]\n",
    "        best_epoch = [0, 0]\n",
    "        bad_counter = 0\n",
    "\n",
    "        for epoch in range(20):\n",
    "            hit, mrr = train_test(model, train_data, test_data)\n",
    "            flag = 0\n",
    "            if hit > best_result[0]:\n",
    "                best_result[0] = hit\n",
    "                best_epoch[0] = epoch\n",
    "                flag = 1\n",
    "            if mrr > best_result[1]:\n",
    "                best_result[1] = mrr\n",
    "                best_epoch[1] = epoch\n",
    "                flag = 1\n",
    "            bad_counter += 1 - flag\n",
    "            if bad_counter >= 5:\n",
    "                break\n",
    "        print('-------------------------------------------------------')\n",
    "        last_sr_gnn_hit.append(hit)\n",
    "        last_sr_gnn_mrr.append(mrr)\n",
    "\n",
    "        df = make_pd_data_frame(train_data_)\n",
    "        knn = cknn.ContextKNN(data = df, session_key='session_id', item_key='item_id', time_key='eventdate')\n",
    "\n",
    "        mrr_20, p_20, scr = knn.multi_predict_ts_data(test_data, 12)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        hit, mrr = [], []\n",
    "        slices = test_data.generate_batch(model.batch_size)\n",
    "\n",
    "        for i in tqdm(slices):\n",
    "            targets, scores = forward(model, i, test_data)\n",
    "            scores = trans_to_cpu(scores).detach().numpy()\n",
    "            for j, idx in enumerate(i):\n",
    "                v = scr[idx][0]\n",
    "                for index, val in zip(list(v.keys()), list(v.values())):\n",
    "                    scores[j,index-1] += val\n",
    "            scores = torch.Tensor(scores)\n",
    "            sub_scores = scores.topk(20)[1]\n",
    "            sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "            for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "                hit.append(np.isin(target - 1, score))\n",
    "                if len(np.where(score == target - 1)[0]) == 0:\n",
    "                    mrr.append(0)\n",
    "                else:\n",
    "                    mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "\n",
    "        final_hit.append(np.mean(hit)*100)\n",
    "        final_mrr.append(np.mean(mrr)*100)\n",
    "\n",
    "        sr_gnn_hit.append(best_result[0])\n",
    "        sr_gnn_mrr.append(best_result[1])\n",
    "\n",
    "        iknn_hit.append(p_20)\n",
    "        iknn_mrr.append(mrr_20)\n",
    "    print()\n",
    "    print('SR-GNN Score: ', np.mean(last_sr_gnn_hit), np.mean(last_sr_gnn_mrr))\n",
    "    print('SR-GNN Last Score: ', np.mean(sr_gnn_hit), np.mean(sr_gnn_mrr))\n",
    "    print('CKNN Score: ', np.mean(iknn_hit), np.mean(iknn_mrr))\n",
    "    print('Proposed Method Score: ',np.mean(final_hit), np.mean(final_mrr))\n",
    "    avg_p.append(np.mean(final_hit))\n",
    "    avg_m.append(np.mean(final_mrr))\n",
    "print('Method 3 Avg Proposed Method Score: ',np.mean(avg_p), np.mean(avg_m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
